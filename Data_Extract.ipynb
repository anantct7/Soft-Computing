{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_extract() :\n",
    "    Data = [];\n",
    "    with open('spam.csv', encoding=\"ISO-8859-1\") as file_csv:\n",
    "        reader_csv = csv.reader(file_csv, delimiter=',')\n",
    "        row_count = 0\n",
    "        for row in reader_csv:\n",
    "            if row_count == 0:\n",
    "                row_count += 1\n",
    "            else:\n",
    "                Data.append(row)\n",
    "                row_count += 1\n",
    "        return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_pre_process(Data) :\n",
    "    Words_stop = [\"\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\",\n",
    "                  \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\",\"i\", \"me\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\",\n",
    "                  \"do\",  \"against\",\"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\",\n",
    "                  \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\",\n",
    "                  \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\",\n",
    "                  \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\",\n",
    "                  \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\",\n",
    "                  \"can\", \"will\", \"just\", \"don\", \"should\",\"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \n",
    "                  \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \n",
    "                  \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\",\n",
    "                  \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\",\n",
    "                  \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\",\n",
    "                  \"are\", \"was\", \"were\", \"now\"]\n",
    "    y = []\n",
    "    for i in range(len(Data)) :\n",
    "        y.append(Data[i][0])\n",
    "    y = np.array(y)\n",
    "    freq_Word = {}\n",
    "    Data_altered = []\n",
    "    for i in range(len(Data)) :\n",
    "        RowData = Data[i][1 : ]\n",
    "        RowData = \" \".join(RowData)\n",
    "        DatanewRow = \"\"\n",
    "        for j in range(len(RowData)) :\n",
    "            if(RowData[j].isalnum() == False) :\n",
    "                res = \" \" \n",
    "            else :\n",
    "                res = RowData[j]\n",
    "            DatanewRow = DatanewRow + res\n",
    "        DatanewRow = DatanewRow.split(\" \")\n",
    "        for j in range(len(DatanewRow)) :\n",
    "            DatanewRow[j] = DatanewRow[j].lower()\n",
    "        altered_Data_new_row = []\n",
    "        set_Word = set()\n",
    "        for j in range(len(DatanewRow)) :\n",
    "            Word = DatanewRow[j]\n",
    "            if(Word in Words_stop) :\n",
    "                continue\n",
    "            else :\n",
    "                set_Word.add(Word)\n",
    "        for Word in set_Word :\n",
    "            altered_Data_new_row.append(Word)\n",
    "        Data_altered.append(altered_Data_new_row)\n",
    "    Data_altered = np.array(Data_altered)\n",
    "    size_train = int((Data_altered.shape[0] * 7) / 10)\n",
    "    train_x_indices = random.sample(range(0, Data_altered.shape[0]), size_train)\n",
    "    train_x, test_x, train_y, test_y = [], [], [], []\n",
    "    for i in range(Data_altered.shape[0]) :\n",
    "        if(i in train_x_indices) :\n",
    "            train_x.append(Data_altered[i])\n",
    "            train_y.append(y[i])\n",
    "        else :\n",
    "            test_x.append(Data_altered[i])\n",
    "            test_y.append(y[i])\n",
    "    train_x = np.array(train_x)\n",
    "    test_x = np.array(test_x)\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "    for i in range(len(train_x)) :\n",
    "        for j in range(len(train_x[i])) :\n",
    "            Word = train_x[i][j]\n",
    "            if(Word not in Words_stop) :\n",
    "                if(Word not in freq_Word) :\n",
    "                    freq_Word[Word] = 1\n",
    "                else:\n",
    "                    freq_Word[Word] = freq_Word[Word] + 1                 \n",
    "    return (train_x, test_x, train_y, test_y, freq_Word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_x(Data, freq_Word) :\n",
    "    Data_new = []\n",
    "    for i in range(Data.shape[0]):\n",
    "        res = []\n",
    "        for Val in freq_Word :\n",
    "            if Val in Data[i] : \n",
    "                res.append(float(1));\n",
    "            else :\n",
    "                res.append(float(0));\n",
    "        res = np.array(res)\n",
    "        Data_new.append(res)\n",
    "\n",
    "    Data_new = np.array(Data_new)\n",
    "    return Data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_y(Data) :\n",
    "    Data_new = []\n",
    "    for i in range(Data.shape[0]) :\n",
    "        if(Data[i] == \"spam\") :\n",
    "            Data_new.append(float(1))\n",
    "        else :\n",
    "            Data_new.append(float(0))\n",
    "    Data_new = np.array(Data_new)\n",
    "    return Data_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
